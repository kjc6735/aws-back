{
    "questions":
        [
            ["한 스타트업이 자동차에 설치된 사물인터넷(IoT) 센서에서 데이터를 수집하는 애플리케이션을 개발했습니다. Amazon Kinesis Data Firehose를 통해 데이터가 Amazon S3로 전송되고 저장됩니다. 매년 데이터는 수십억 개의 S3 객체를 생성합니다. 매일 아침 비즈니스는 이전 30일 동안의 데이터를 사용하여 일련의 기계 학습(ML) 모델을 재교육합니다.\n회사는 1년에 4번 이전 12개월의 데이터를 사용하여 다른 기계 학습 모델을 분석하고 교육합니다. 데이터는 최대 1년 동안 최소한의 지연으로 액세스할 수 있어야 합니다. 데이터는 1년 후에 아카이브를 위해 보존해야 합니다.\n\n비용 효율성 측면에서 이러한 기준을 가장 잘 충족하는 스토리지 시스템은 무엇입니까?\n\nA. S3 Intelligent-Tiering 스토리지 클래스를 사용하십시오. S3 수명 주기 정책을 생성하여 1년 후 객체를 S3 Glacier Deep Archive로 전환합니다.\nB. S3 Intelligent-Tiering 스토리지 클래스를 사용합니다. 1년 후에 객체를 자동으로 S3 Glacier Deep Archive로 이동하도록 S3 Intelligent-Tiering을 구성합니다.\nC. S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스를 사용합니다. S3 수명 주기 정책을 생성하여 1년 후 객체를 S3 Glacier Deep Archive로 전환합니다.\nD. S3 Standard 스토리지 클래스를 사용합니다. S3 수명 주기 정책을 생성하여 30일 후에 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하고 1년 후에 S3 Glacier Deep Archive로 전환합니다.\n", "A startup has developed an application that gathers data from Internet of Things (IoT) sensors installed on autos. Through Amazon Kinesis Data Firehose, the data is transmitted to and stored in Amazon S3. Each year, data generates billions of S3 objects. Each morning, the business retrains a set of machine learning (ML) models using data from the preceding 30 days.\nFour times a year, the corporation analyzes and trains other machine learning models using data from the preceding 12 months. The data must be accessible with a minimum of delay for a period of up to one year. Data must be preserved for archive reasons after one year.\n\nWhich storage system best satisfies these criteria in terms of cost-effectiveness?\n\nA. Use the S3 Intelligent-Tiering storage class. Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 1 year.\nB. Use the S3 Intelligent-Tiering storage class. Configure S3 Intelligent-Tiering to automativally move objects to S3 Glacier Deep Archive after 1 year.\nC. Use the S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 1 year.\nD. Use the S3 Standard storage class. Create an S3 Lifecycle policy to transition objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days, and then to S3 Glacier Deep Archive after 1 year.\n","D"], ["비즈니스에는 Amazon S3에 데이터 스토리지가 필요합니다. 규정 준수 요구 사항은 개체가 수정될 때 원래 상태를 유지해야 한다고 규정합니다. 또한 5년 이상 된 데이터는 감사 목적으로 보관해야 합니다.\n\n솔루션 아키텍트가 가장 노력하기 위해 추천해야 하는 것은 무엇입니까?\n\nA. 거버넌스 모드에서 객체 수준 버전 관리 및 S3 객체 잠금 활성화\nB. 규정 준수 모드에서 객체 수준 버전 관리 및 S3 객체 잠금 활성화\nC. 개체 수준 버전 관리를 활성화합니다. 수명 주기 정책을 활성화하여 5년 이상 된 데이터를 S3 Glacier Deep Archive로 이동\nD. 개체 수준 버전 관리를 활성화합니다. 수명 주기 정책을 활성화하여 5년 이상 된 데이터를 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동합니다.\n", "A business requires data storage on Amazon S3. A compliance requirement stipulates that when objects are modified, their original state must be retained. Additionally, data older than five years should be kept for auditing purposes.\n\nWhat SHOULD A SOLUTIONS ARCHITECT RECOMMEND AS THE MOST EFFORTABLE?\n\nA. Enable object-level versioning and S3 Object Lock in governance mode\nB. Enable object-level versioning and S3 Object Lock in compliance mode\nC. Enable object-level versioning. Enable a lifecycle policy to move data older than 5 years to S3 Glacier Deep Archive\nD. Enable object-level versioning. Enable a lifecycle policy to move data older than 5 years to S3 Standard-Infrequent Access (S3 Standard-IA)\n","C"],
             ["여러 Amazon EC2 인스턴스는 애플리케이션을 호스팅하는 데 사용됩니다. 이 프로그램은 Amazon SQS 대기열에서 메시지를 읽고 Amazon RDS 데이터베이스에 쓴 다음 대기열에서 제거합니다. RDS 테이블에 중복 항목이 포함되는 경우가 있습니다. SQS 대기열에는 중복 메시지가 없습니다.\n\n솔루션 설계자는 메시지가 한 번만 처리되도록 어떻게 보장할 수 있습니까?\n\nA. CreateQueue API 호출을 사용하여 새 대기열을 만듭니다.\nB. AddPermission API 호출을 사용하여 적절한 권한을 추가합니다.\nC. ReceiveMessage API 호출을 사용하여 적절한 대기 시간을 설정합니다.\nD. ChangeMessageVisibility API 호출을 사용하여 가시성 시간 초과를 늘립니다.\n", "Multiple Amazon EC2 instances are used to host an application. The program reads messages from an Amazon SQS queue, writes them to an Amazon RDS database, and then removes them from the queue. The RDS table sometimes contains duplicate entries. There are no duplicate messages in the SQS queue.\n\nHow can a solutions architect guarantee that messages are handled just once?\n\nA. Use the CreateQueue API call to create a new queue.\nB. Use the AddPermission API call to add appropriate permissions.\nC. Use the ReceiveMessage API call to set an appropriate wait time.\nD. Use the ChangeMessageVisibility API call to increase the visibility timeout.\n","D. 메시지를 처리하는데 오랜 시간이 걸리면, 한 인스턴스가 작업을 처리하는 동안 SQS는 해당 인스턴스가 작업을 처리하다가 죽었다고 판단해서 메시지를 다시 살림. 이 인터벌을 조절하는게 가시성 시간 초과 이므로 늘려야 함."],
              ["한 기업이 소매 웹사이트의 전 세계 출시를 발표했습니다. 웹사이트는 Elastic Load Balancer를 통해 라우팅되는 수많은 Amazon EC2 인스턴스에서 호스팅됩니다. 인스턴스는 Auto Scaling 그룹의 여러 가용 영역에 분산됩니다.\n회사는 고객이 웹사이트를 보는 장치에 따라 맞춤형 자료를 제공하기를 원합니다.\n\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계를 함께 수행해야 합니까? (2개를 선택하세요.)\n\nA. 여러 버전의 콘텐츠를 캐시하도록 Amazon CloudFront를 구성합니다.\nB. 네트워크 로드 밸런서에서 호스트 헤더를 구성하여 트래픽을 다른 인스턴스로 전달합니다.\nC. User-Agent 헤더를 기반으로 특정 객체를 사용자에게 보내도록 Lambda@Edge 함수를 구성합니다 .\nD. AWS Global Accelerator를 구성합니다. NLB(Network Load Balancer)로 요청을 전달합니다. 다른 EC2 인스턴스에 대한 호스트 기반 라우팅을 설정하도록 NLB를 구성합니다.\nE. AWS Global Accelerator를 구성합니다. NLB(Network Load Balancer)로 요청을 전달합니다. 다른 EC2 인스턴스에 대한 경로 기반 라우팅을 설정하도록 NLB를 구성합니다.\n", "A corporation just announced the worldwide launch of their retail website. The website is hosted on numerous Amazon EC2 instances, which are routed via an Elastic Load Balancer. The instances are distributed across several Availability Zones in an Auto Scaling group.\nThe firm want to give its clients with customized material depending on the device from which they view the website.\n\nWhich steps should a solutions architect perform in combination to satisfy these requirements? (Select two.)\n\nA. Configure Amazon CloudFront to cache multiple versions of the content.\nB. Configure a host header in a Network Load Balancer to forward traffic to different instances.\nC. Configure a Lambda@Edge function to send specific objects to users based on the User-Agent header.\nD. Configure AWS Global Accelerator. Forward requests to a Network Load Balancer (NLB). Configure the NLB to set up host-based routing to different EC2 instances.\nE. Configure AWS Global Accelerator. Forward requests to a Network Load Balancer (NLB). Configure the NLB to set up path-based routing to different EC2 instances.\n","A, C. 7계층 헤더 정보가 필요하므로 NLB사용 불가."], ["실험과 민첩성을 촉진하기 위해 비즈니스에서는 개발자가 현재 IAM 정책을 기존 IAM 역할에 연결할 수 있습니다. 반면 보안 운영 팀은 개발자가 현재 관리자 정책을 첨부하여 다른 보안 규칙을 우회할 수 있다고 우려하고 있습니다.\n\n솔루션 설계자는 이 문제를 처리할 때 어떤 접근 방식을 사용해야 합니까?\n\nA. 개발자가 새 정책을 생성할 때마다 알림을 보내도록 Amazon SNS 주제를 생성합니다.\nB. 서비스 제어 정책을 사용하여 조직 단위의 모든 계정에서 IAM 활동을 비활성화합니다.\nC. 개발자가 정책을 첨부하지 못하도록 하고 모든 IAM 업무를 보안 운영 팀에 할당합니다.\nD. 관리자 정책 연결을 명시적으로 거부하는 개발자 IAM 역할에 대한 IAM 권한 경계를 설정합니다.\n", "To facilitate experimentation and agility, a business enables developers to link current IAM policies to existing IAM roles. The security operations team, on the other hand, is worried that the developers may attach the current administrator policy, allowing them to bypass any other security rules.\n\nWhat approach should a solutions architect use in dealing with this issue?\n\nA. Create an Amazon SNS topic to send an alert every time a developer creates a new policy.\nB. Use service control policies to disable IAM activity across all account in the organizational unit.\nC. Prevent the developers from attaching any policies and assign all IAM duties to the security operations team.\nD. Set an IAM permissions boundary on the developer IAM role that explicitly denies attaching the administrator policy.\n","D. 권한 경계를 통해 부여할 수 있는 최대 권한 제한\n* 경계는 그룹이 아닌 사용자와 역할에만 할당 가능"], ["새로 형성된 회사는 3계층 웹 애플리케이션을 개발했습니다. 프런트 엔드는 완전히 정적 정보로 구성됩니다. 마이크로서비스는 애플리케이션 계층을 형성합니다. 사용자 데이터는 최소한의 지연으로 액세스할 수 있는 JSON 문서 형식으로 보관됩니다. 회사는 첫 해에 월별 트래픽 급증과 함께 최소한의 정규 트래픽을 예상합니다. 스타트업 팀의 운영 간접비는 최소한으로 유지되어야 합니다.\n\n솔루션 설계자는 이를 달성하기 위한 수단으로 무엇을 제안해야 합니까?\n\nA. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드를 저장하고 제공합니다. 애플리케이션 계층에 AWS Elastic Beanstalk를 사용합니다. Amazon DynamoDB를 사용하여 사용자 데이터를 저장합니다.\nB. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드를 저장하고 제공합니다. 애플리케이션 계층에 Amazon Elastic KubernetesService(Amazon EKS)를 사용합니다. Amazon DynamoDB를 사용하여 사용자 데이터를 저장합니다.\nC. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드를 저장하고 제공합니다. 애플리케이션 계층에 Amazon API Gateway 및 AWS Lambda 함수를 사용합니다. Amazon DynamoDB를 사용하여 사용자 데이터를 저장합니다.\nD. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드를 저장하고 제공합니다. 애플리케이션 계층에 Amazon API Gateway 및 AWS Lambda 함수를 사용합니다. 읽기 전용 복제본과 함께 Amazon RDS를 사용하여 사용자 데이터를 저장합니다.\n", "A newly formed company developed a three-tiered web application. The front end is comprised entirely of static information. Microservices form the application layer. User data is kept in the form of JSON documents that must be accessible with a minimum of delay. The firm anticipates minimal regular traffic in the first year, with monthly traffic spikes. The startup team's operational overhead expenditures must be kept to a minimum.\n\nWhat should a solutions architect suggest as a means of achieving this?\n\nA. Use Amazon S3 static website hosting to store and serve the front end. Use AWS Elastic Beanstalk for the application layer. Use Amazon DynamoDB to store user data.\nB. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon Elastic KubernetesService (Amazon EKS) for the application layer. Use Amazon DynamoDB to store user data.\nC. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon API Gateway and AWS Lambda functions for the application layer. Use Amazon DynamoDB to store user data.\nD. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon API Gateway and AWS Lambda functions for the application layer. Use Amazon RDS with read replicas to store user data.\n","C. json 데이터이므로 DynamoDB 사용해야하고, 가장 저렴하게 app layer 구현할 수 있는건 lambda"],
             ["Amazon Elastic Container Service(Amazon ECS) 컨테이너 인스턴스는 ALB(Application Load Balancer) 뒤에 전자 상거래 웹 사이트의 웹 애플리케이션을 설치하는 데 사용됩니다. 사용량이 많은 순간에는 웹 사이트 속도가 느려지고 가용성이 감소합니다. 솔루션 설계자는 Amazon CloudWatch 경보를 활용하여 가용성 문제가 발생할 때 알림을 받고 리소스를 확장할 수 있습니다. 비즈니스 경영진은 이러한 상황에 자동으로 대응하는 시스템을 원합니다.\n\n어떤 솔루션이 이러한 기준을 충족합니까?\n\nA. ALB에 시간 초과가 있을 때 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정합니다. CPU 또는 메모리 예약이 너무 높을 때 ECS 클러스터를 확장하도록 AWS Auto Scaling을 설정합니다.\nB. ALB CPU 사용률이 너무 높을 때 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정합니다. CPU 또는 메모리 예약이 너무 높을 때 ECS 클러스터를 확장하도록 AWS Auto Scaling을 설정합니다.\nC. 서비스의 CPU 사용률이 너무 높을 때 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정합니다. CPU 또는 메모리 예약이 너무 높을 때 ECS 클러스터를 확장하도록 AWS Auto Scaling을 설정합니다.\nD. ALB 대상 그룹 CPU 사용률이 너무 높을 때 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정합니다. CPU 또는 메모리 예약이 너무 높을 때 ECS 클러스터를 확장하도록 AWS Auto Scaling을 설정합니다.\n", "Amazon Elastic Container Service (Amazon ECS) container instances are used to install an ecommerce website's web application behind an Application Load Balancer (ALB). The website slows down and availability is decreased during moments of heavy usage. A solutions architect utilizes Amazon CloudWatch alarms to be notified when an availability problem occurs, allowing them to scale out resources. The management of the business want a system that automatically reacts to such circumstances.\n\nWhich solution satisfies these criteria?\n\nA. Set up AWS Auto Scaling to scale out the ECS service when there are timeouts on the ALB. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.\nB. Set up AWS Auto Scaling to scale out the ECS service when the ALB CPU utilization is too high. Setup AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.\nC. Set up AWS Auto Scaling to scale out the ECS service when the service's CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.\nD. Set up AWS Auto Scaling to scale out the ECS service when the ALB target group CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.\n","C"], ["기업은 Site-to-Site VPN 연결을 사용하여 온프레미스에서 AWS 클라우드 서비스에 안전하게 액세스할 수 있도록 합니다. Amazon EC2 인스턴스에 대한 VPN 연결을 통한 트래픽 증가로 인해 사용자가 VPN 연결 속도가 느려지고 있습니다.\n\n어떤 접근 방식이 VPN 처리량을 증가시킬까요?\n\nA. 처리량을 확장하려면 동일한 네트워크에 대해 여러 고객 게이트웨이를 구현하십시오.\nB. 동일한 비용의 다중 경로 라우팅이 있는 전송 게이트웨이를 사용하고 VPN 터널을 추가합니다.\nC. 동일한 비용의 다중 경로 라우팅 및 다중 채널을 사용하여 가상 사설 게이트웨이를 구성합니다.\nD. 기본 제한 이상으로 처리량을 확장하려면 VPN 구성의 터널 수를 늘립니다.\n", "A business uses Site-to-Site VPN connections to provide safe access to AWS Cloud services from on-premises. Users are experiencing slower VPN connectivity as a result of increased traffic through the VPN connections to the Amazon EC2 instances.\n\nWhich approach will result in an increase in VPN throughput?\n\nA. Implement multiple customer gateways for the same network to scale the throughput.\nB. Use a transit gateway with equal cost multipath routing and add additional VPN tunnels.\nC. Configure a virtual private gateway with equal cost multipath routing and multiple channels.\nD. Increase the number of tunnels in the VPN configuration to scale the throughput beyond the default limit.\n"]]}